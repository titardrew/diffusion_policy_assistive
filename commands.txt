# ---- DATA COLLECTION ----

    # collect a ppo_150 (#1) dataset with the ppo model
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_150.zarr --load-policy-path ./submodules/assistive-gym/trained_models/ppo/FeedingJaco-v1/checkpoint_000053/ --algo ppo --env FeedingJaco-v1 --episodes 150

    # collect a sac_150 (#2) dataset with the sac model
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/sac_150.zarr --load-policy-path ./submodules/assistive-gym/trained_models/sac/FeedingJaco-v1/checkpoint_005163/ --algo sac --env FeedingJaco-v1 --episodes 150
    
    # get a ppo_150_sac_150 (#3) dataset
PYTHONPATH="." python diffusion_policy/scripts/cat_stores.py -i tmp_dataset/ppo_150.zarr tmp_dataset/sac_150.zarr -o tmp_dataset/ppo_150_sac_150.zarr
    
    # collect a ppo_150_r130 (#4) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_150_r130.zarr --load-policy-path ./submodules/assistive-gym/trained_models/ppo/FeedingJaco-v1/checkpoint_000053/ --algo ppo --env FeedingJaco-v1 --episodes 150 --min-reward 130
    
    # collect a ppo_150_r120 (#5) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_150_r130.zarr --load-policy-path ./submodules/assistive-gym/trained_models/ppo/FeedingJaco-v1/checkpoint_000053/ --algo ppo --env FeedingJaco-v1 --episodes 150 --min-reward 120

    # collect a sac_150_r130 (#6) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/sac_150_r130.zarr --load-policy-path ./submodules/assistive-gym/trained_models/sac/FeedingJaco-v1/checkpoint_005163/ --algo sac --env FeedingJaco-v1 --episodes 150 --min-reward 130 
    
    # collect a sac_150_r120 (#7) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/sac_150_r130.zarr --load-policy-path ./submodules/assistive-gym/trained_models/sac/FeedingJaco-v1/checkpoint_005163/ --algo sac --env FeedingJaco-v1 --episodes 150 --min-reward 120 
    
    # get a ppo_150_sac_150_r130 (#8) dataset
PYTHONPATH="." python diffusion_policy/scripts/cat_stores.py -i tmp_dataset/ppo_150_r130.zarr tmp_dataset/sac_150_r130.zarr -o tmp_dataset/ppo_150_sac_150_r130.zarr
    
    # get a ppo_150_sac_150_r120 (#9) dataset
PYTHONPATH="." python diffusion_policy/scripts/cat_stores.py -i tmp_dataset/ppo_150_r120.zarr tmp_dataset/sac_150_r120.zarr -o tmp_dataset/ppo_150_sac_150_r120.zarr
    
    # get a ppo_400k_150_r120 (#10) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_400k_150_r120.zarr --load-policy-path ./submodules/assistive-gym/trained_models_underfit/ppo/FeedingJaco-v1/checkpoint_000021/ --algo ppo --env FeedingJaco-v1 --episodes 150 --min-reward 120 

    # collect a ppo_1000 (#11) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_1000.zarr --load-policy-path ./submodules/assistive-gym/trained_models_underfit/ppo/FeedingJaco-v1/checkpoint_000021/ --algo ppo --env FeedingJaco-v1 --episodes 1000

    # collect a ppo_400k_1000 (#12) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_400k_1000.zarr --load-policy-path ./submodules/assistive-gym/trained_models_underfit/ppo/FeedingJaco-v1/checkpoint_000021/ --algo ppo --env FeedingJaco-v1 --episodes 1000

    # collect a ppo_400k_1000_r100 (#??) dataset
    # PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ppo_400k_1000_r100.zarr --load-policy-path ./submodules/assistive-gym/trained_models_underfit/ppo/FeedingJaco-v1/checkpoint_000021/ --algo ppo --env FeedingJaco-v1 --episodes 1000 --min-reward 100

    # RETIRED
    # collect a ScratchItch_ppo (#15) dataset
#PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ScratchItch_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models/ppo/ScratchItchJaco-v1/checkpoint_000053/ --algo ppo --env ScratchItchJaco-v1 --episodes 1000

    # RETIRED
    # collect a ArmManipulation_ppo (#16) dataset
#PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ArmManipulation_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models/ppo/ArmManipulationJaco-v1/checkpoint_000053/ --algo ppo --env ArmManipulationJaco-v1 --episodes 1000
    
    # collect a ScratchItch_ppo (#15) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ScratchItch_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models_strip/ppo/ScratchItchJaco-v1/checkpoint_000131/ --algo ppo --env ScratchItchJaco-v1 --episodes 1000
    
    # collect a ArmManipulation_ppo (#16) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/ArmManipulation_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models_strip/ppo/ArmManipulationJaco-v1/checkpoint_000131/ --algo ppo --env ArmManipulationJaco-v1 --episodes 1000
    
    # collect a BedBathing_ppo (#17) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/BedBathing_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models_strip/ppo/BedBathingJaco-v1/checkpoint_000131/ --algo ppo --env BedBathingJaco-v1 --episodes 1000
    
    # collect a Drinking_ppo (#18) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/Drinking_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models_strip/ppo/DrinkingJaco-v1/checkpoint_000131/ --algo ppo --env DrinkingJaco-v1 --episodes 1000 --render-episodes 5

    # collect a Drinking_1000k_ppo (#19) dataset
PYTHONPATH="." python diffusion_policy/scripts/assistive_collect.py --output_path tmp_dataset/Drinking_1000k_ppo.zarr --load-policy-path ./submodules/assistive-gym/trained_models_1000k/ppo/DrinkingJaco-v1/checkpoint_000053/ --algo ppo --env DrinkingJaco-v1 --episodes 1000 --render-episodes 5


# ---- GDRIVE ----
    # We use GDrive to store data. See: https://github.com/glotlabs/gdrive/tree/main
    # You'll have to create Google API Creds (OAuth). It's a bit tedious but fairly quick. See: https://github.com/glotlabs/gdrive/blob/main/docs/create_google_api_credentials.md

    # Import creds
./gdrive account import gdrive_export-titarenkoan_gmail_com.tar

    # Make experiment dir, parent is always the same
./gdrive files mkdir --parent 1nv575YO-_CkBa9eljwhqvCKxEtvMzPqJ Jan25_First_Run

    # Upload a checkpoint, parent id is output by the mkdir
./gdrive files upload --parent 1tdh25aw4JadSiBXj5gyCFU1ER1PFRBkM --recursive diffusion_policy_assistive/data/outputs/2024.01.25/09.27.05_train_diffusion_transformer_lowdim_assistive_feeding_jaco_lowdim/checkpoints/

    # Upload a dataset, parent id is always the same
./gdrive files upload --parent 1tndEZ3m_MpQ68DxWK-PTEd9I6UPYRyht --recursive diffusion_policy_assistive/tmp_dataset/ppo_150.zarr

    # Download a dataset
./gdrive files download 13cG8YHoUitmnul9spjygWLV-lBo-SxAA --recursive --destination tmp_dataset/


# ---- TRAIN DIFFUSION ----

    # Jan 26 experiment #1 (PPO-150 dataset).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_150.zarr

    # Jan 27 experiment #2 (PPO-SAC-150 dataset).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_150_sac_150.zarr
    
    # Jan 29 experiment #3 (Reward filtering).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_150_r130.zarr
    
    # Jan 29 experiment #4 (Reward filtering. Combined PPO/SAC).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_150_sac_150_r130.zarr

    # Jan 29 experiment #5 (Underfitted PPO).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_400k_150_r120.zarr

    # Jan 29 experiment #6 (Observation steps tuning).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_150.zarr n_obs_steps=4
    
    # experiment #7 (More data PPO).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_more_data_ppo_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_1000.zarr
    
    # experiment #8 (More data PPO underfitted).
HYDRA_FULL_ERROR=1 PYTHONPATH="." python train.py --config-dir=diffusion_policy/config/ --config-name=train_diffusion_transformer_lowdim_assistive_workspace.yaml training.seed=42 training.device=cuda:0 hydra.run.dir='data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_more_data_ppo_unerf_${name}_${task_name}' task.dataset_path=tmp_dataset/ppo_400k_1000.zarr

    # Further are in the experiments doc.


# ----- Safety Models ------
# feeding 250
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1/horizon_10_n_obs_1_n_act_2/checkpoints/best.ckpt -o out/feeding_250_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1/horizon_10_n_obs_1_n_act_2/checkpoints/best.ckpt -o out/feeding_250_state_predictor --safety_model feeding_250_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1/horizon_10_n_obs_1_n_act_2/checkpoints/best.ckpt -o out/feeding_250_vae --safety_model feeding_250_vae
# feeding 100
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-100/horizon_10_n_obs_2_n_act_2/checkoint/best.ckpt -o out/feeding_100_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-100/horizon_10_n_obs_2_n_act_2/checkoint/best.ckpt -o out/feeding_100_state_predictor --safety_model feeding_100_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-100/horizon_10_n_obs_2_n_act_2/checkoint/best.ckpt -o out/feeding_100_vae --safety_model feeding_100_vae
# feeding 50
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-50/horizon_10_n_obs_2_n_act_2/checkpoint/best.ckpt -o out/feeding_50_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-50/horizon_10_n_obs_2_n_act_2/checkpoint/best.ckpt -o out/feeding_50_state_predictor --safety_model feeding_50_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-50/horizon_10_n_obs_2_n_act_2/checkpoint/best.ckpt -o out/feeding_50_vae --safety_model feeding_50_vae
# drinking
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/DrinkingJaco_1kk/latest.ckpt -o out/drinking_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/DrinkingJaco_1kk/latest.ckpt -o out/drinking_state_predictor --safety_model drinking_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/DrinkingJaco_1kk/latest.ckpt -o out/drinking_vae --safety_model drinking_vae
# arm_manipulation
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ArmManipulationJaco_2.5kk/latest.ckpt -o out/arm_manipulation_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ArmManipulationJaco_2.5kk/latest.ckpt -o out/arm_manipulation_state_predictor --safety_model arm_manipulation_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ArmManipulationJaco_2.5kk/latest.ckpt -o out/arm_manipulation_vae --safety_model arm_manipulation_vae
# scratch_itch
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ScratchItchJaco_2.5kk/latest.ckpt -o out/scratch_itch_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ScratchItchJaco_2.5kk/latest.ckpt -o out/scratch_itch_state_predictor --safety_model scratch_itch_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ScratchItchJaco_2.5kk/latest.ckpt -o out/scratch_itch_vae --safety_model scratch_itch_vae
# bed_bathing
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/BedBathing_2.5kk/latest.ckpt -o out/bed_bathing_none
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/BedBathing_2.5kk/latest.ckpt -o out/bed_bathing_state_predictor --safety_model bed_bathing_state_predictor
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/BedBathing_2.5kk/latest.ckpt -o out/bed_bathing_vae --safety_model bed_bathing_vae

PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path teleop_datasets/FeedingJaco-v1.zarr/ --save_path feeding_250_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path teleop_datasets/FeedingJaco-v1_100.zarr/ --save_path feeding_100_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path teleop_datasets/FeedingJaco-v1_50.zarr/ --save_path feeding_50_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path /home/aty/Data/AssistiveDiffusion/Datasets/Drinking_1000k_ppo.zarr/ --save_path drinking_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path /home/aty/Data/AssistiveDiffusion/Datasets/ArmManipulation_ppo.zarr/ --save_path arm_manipulation_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path /home/aty/Data/AssistiveDiffusion/Datasets/ScratchItch_ppo.zarr/ --save_path scratch_itch_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path /home/aty/Data/AssistiveDiffusion/Datasets/BedBathing_ppo.zarr/ --save_path bed_bathing_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
# feeding 250
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1/horizon_10_n_obs_1_n_act_2/checkpoints/best.ckpt -o out/feeding_250_state_predictor_ss --safety_model feeding_250_state_predictor_ss
# feeding 100
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-100/horizon_10_n_obs_2_n_act_2/checkoint/best.ckpt -o out/feeding_100_state_predictor_ss --safety_model feeding_100_state_predictor_ss
# feeding 50
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/TeleopDPCheckpoints/FeedingJaco-v1-50/horizon_10_n_obs_2_n_act_2/checkpoint/best.ckpt -o out/feeding_50_state_predictor_ss --safety_model feeding_50_state_predictor_ss
# drinking
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/DrinkingJaco_1kk/latest.ckpt -o out/drinking_state_predictor_ss --safety_model drinking_state_predictor_ss
# arm_manipulation
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ArmManipulationJaco_2.5kk/latest.ckpt -o out/arm_manipulation_state_predictor_ss --safety_model arm_manipulation_state_predictor_ss
# scratch_itch
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/ScratchItchJaco_2.5kk/latest.ckpt -o out/scratch_itch_state_predictor_ss --safety_model scratch_itch_state_predictor_ss
# bed_bathing
HYDRA_FULL_ERROR=1 PYTHONPATH="." python eval.py -d cuda --n_tests 200 -c /home/aty/Data/AssistiveDiffusion/Experiments/BedBathing_2.5kk/latest.ckpt -o out/bed_bathing_state_predictor_ss --safety_model bed_bathing_state_predictor_ss


# voraus-like test commands

PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --zarr_path teleop_datasets/FeedingJaco-v1.zarr/ --test_parquet_path parquet_datasets/feeding_250_test.parquet --save_path feeding_250_ensemble_state_prediction_sm_To1_Ta1_H2_O1_.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5
PYTHONPATH="." python diffusion_policy/scripts/assistive_train_safety_model.py --env_type BedBathing --zarr_path /home/aty/Data/AssistiveDiffusion/Datasets/BedBathing_ppo.zarr/ --test_parquet_path parquet_datasets/bed_bathing_test.parquet --save_path bed_bathing_ensemble_state_prediction_sm_To1_Ta1_H2_O1.pth --horizon 2 --out_obs_horizon 1 --in_obs_horizon 1 --in_act_horizon 1 --model_type state_predictor --ensemble_size 5